# å¼€å‘è€…æŒ‡å— - åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ

## ğŸ¯ å¼€å‘ç¯å¢ƒè®¾ç½®

### ç³»ç»Ÿè¦æ±‚

```bash
# å¿…éœ€å·¥å…·
- Rust 1.70+
- PostgreSQL 13+
- RabbitMQ 3.8+
- Docker & Docker Compose
- Git

# å¯é€‰å·¥å…·
- Redis 6.0+ (ç¼“å­˜æ”¯æŒ)
- kubectl (Kuberneteséƒ¨ç½²)
- cargo-watch (è‡ªåŠ¨é‡å»º)
```

### å¼€å‘ç¯å¢ƒåˆå§‹åŒ–

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd scheduler

# 2. å®‰è£…Rustå·¥å…·é“¾
rustup component add rustfmt clippy
cargo install cargo-watch cargo-expand

# 3. å¯åŠ¨å¼€å‘ä¾èµ–
docker-compose -f docker-compose.dev.yml up -d

# 4. ç¯å¢ƒå˜é‡é…ç½®
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶è®¾ç½®å¿…è¦å˜é‡

# 5. æ•°æ®åº“åˆå§‹åŒ–
cargo run --bin migrate

# 6. éªŒè¯ç¯å¢ƒ
cargo test --all
```

## ğŸ—ï¸ é¡¹ç›®æ¶æ„æ·±å…¥è§£æ

### Crateä¾èµ–å…³ç³»å›¾

```mermaid
graph TD
    A[scheduler-errors] --> B[scheduler-domain]
    B --> C[scheduler-core]
    C --> D[scheduler-application]
    C --> E[scheduler-infrastructure]
    F[scheduler-config] --> E
    G[scheduler-observability] --> C
    D --> H[scheduler-api]
    D --> I[scheduler-dispatcher]
    D --> J[scheduler-worker]
    E --> H
    E --> I
    E --> J
```

### å±‚æ¬¡æ¶æ„è¯´æ˜

#### 1. åŸºç¡€å±‚ (Foundation Layer)
```rust
// scheduler-errors: ç»Ÿä¸€é”™è¯¯å¤„ç†
pub enum SchedulerError {
    ValidationError(String),
    DatabaseError(String),
    MessageQueueError(String),
    // ...
}

// scheduler-domain: ä¸šåŠ¡é¢†åŸŸæ¨¡å‹
pub struct Task {
    pub id: Option<i64>,
    pub name: String,
    pub executor: String,
    // ...
}

// scheduler-core: ä¾èµ–æ³¨å…¥å’ŒæœåŠ¡æŠ½è±¡
pub struct Container {
    services: HashMap<TypeId, Arc<dyn Any + Send + Sync>>,
}
```

#### 2. åº”ç”¨å±‚ (Application Layer)
```rust
// scheduler-application: ä¸šåŠ¡æœåŠ¡å®ç°
#[async_trait]
impl TaskControlService for TaskService {
    async fn create_task(&self, request: CreateTaskRequest) -> SchedulerResult<Task> {
        // 1. éªŒè¯è¾“å…¥
        self.validate_task_request(&request)?;
        
        // 2. ä¸šåŠ¡é€»è¾‘å¤„ç†
        let task = Task::from_request(request);
        
        // 3. æŒä¹…åŒ–
        self.repository.save(&task).await?;
        
        // 4. å‘å¸ƒäº‹ä»¶
        self.event_publisher.publish(TaskCreated { task_id: task.id }).await?;
        
        Ok(task)
    }
}
```

#### 3. åŸºç¡€è®¾æ–½å±‚ (Infrastructure Layer)
```rust
// scheduler-infrastructure: å…·ä½“å®ç°
impl TaskRepository for PostgreSQLTaskRepository {
    async fn save(&self, task: &Task) -> SchedulerResult<Task> {
        let query = sqlx::query!(
            "INSERT INTO tasks (name, executor, command) VALUES ($1, $2, $3) RETURNING id",
            task.name,
            task.executor,
            task.command
        );
        
        let row = query.fetch_one(&self.pool).await
            .map_err(|e| SchedulerError::DatabaseError(e.to_string()))?;
            
        Ok(Task { id: Some(row.id), ..task.clone() })
    }
}
```

## ğŸ”§ æ ¸å¿ƒå¼€å‘æ¨¡å¼

### 1. ä¾èµ–æ³¨å…¥æ¨¡å¼

```rust
// æœåŠ¡æ³¨å†Œ
let mut container = Container::new();
container.register::<dyn TaskRepository>(Arc::new(PostgreSQLTaskRepository::new(pool)));
container.register::<dyn MessageQueue>(Arc::new(RabbitMQMessageQueue::new(connection)));

// æœåŠ¡è§£æ
let task_repo = container.resolve::<dyn TaskRepository>()?;
let message_queue = container.resolve::<dyn MessageQueue>()?;

let task_service = TaskService::new(task_repo, message_queue);
```

### 2. ä»“å‚¨æ¨¡å¼ (Repository Pattern)

```rust
// æŠ½è±¡æ¥å£
#[async_trait]
pub trait TaskRepository: Send + Sync {
    async fn find_by_id(&self, id: i64) -> SchedulerResult<Option<Task>>;
    async fn save(&self, task: &Task) -> SchedulerResult<Task>;
    async fn delete(&self, id: i64) -> SchedulerResult<()>;
}

// å…·ä½“å®ç°
pub struct PostgreSQLTaskRepository {
    pool: PgPool,
}

#[async_trait]
impl TaskRepository for PostgreSQLTaskRepository {
    async fn find_by_id(&self, id: i64) -> SchedulerResult<Option<Task>> {
        // å®ç°ç»†èŠ‚
    }
}
```

### 3. äº‹ä»¶é©±åŠ¨æ¨¡å¼

```rust
// äº‹ä»¶å®šä¹‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskCreated {
    pub task_id: i64,
    pub task_name: String,
    pub created_at: DateTime<Utc>,
}

// äº‹ä»¶å‘å¸ƒ
pub struct EventPublisher {
    message_queue: Arc<dyn MessageQueue>,
}

impl EventPublisher {
    pub async fn publish<T: Event>(&self, event: T) -> SchedulerResult<()> {
        let message = Message::new(event)?;
        self.message_queue.publish("events", message).await
    }
}

// äº‹ä»¶å¤„ç†
#[async_trait]
pub trait EventHandler<T: Event>: Send + Sync {
    async fn handle(&self, event: T) -> SchedulerResult<()>;
}
```

## ğŸ“Š æ•°æ®å±‚å¼€å‘æŒ‡å—

### æ•°æ®åº“è¿ç§»

```sql
-- migrations/001_initial_schema.sql
CREATE TABLE tasks (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL UNIQUE,
    description TEXT,
    task_type VARCHAR(100) NOT NULL,
    executor VARCHAR(100) NOT NULL,
    command TEXT NOT NULL,
    arguments JSONB,
    schedule VARCHAR(255),
    priority VARCHAR(20) DEFAULT 'normal',
    status VARCHAR(20) DEFAULT 'created',
    retry_count INTEGER DEFAULT 0,
    timeout_seconds INTEGER DEFAULT 3600,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    CONSTRAINT valid_priority CHECK (priority IN ('low', 'normal', 'high', 'critical'))
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_priority ON tasks(priority);
CREATE INDEX idx_tasks_schedule ON tasks(schedule) WHERE schedule IS NOT NULL;
```

### æŸ¥è¯¢æ„å»ºå™¨

```rust
pub struct TaskQueryBuilder {
    query: String,
    params: Vec<Box<dyn ToSql + Send + Sync>>,
    where_clauses: Vec<String>,
}

impl TaskQueryBuilder {
    pub fn new() -> Self {
        Self {
            query: "SELECT * FROM tasks".to_string(),
            params: Vec::new(),
            where_clauses: Vec::new(),
        }
    }
    
    pub fn with_status(mut self, status: TaskStatus) -> Self {
        self.where_clauses.push(format!("status = ${}", self.params.len() + 1));
        self.params.push(Box::new(status.to_string()));
        self
    }
    
    pub async fn execute<'a, E>(&self, executor: E) -> SchedulerResult<Vec<Task>>
    where
        E: Executor<'a, Database = Postgres>,
    {
        let query = self.build_query();
        let rows = sqlx::query_as::<_, Task>(&query)
            .fetch_all(executor)
            .await?;
        Ok(rows)
    }
}
```

### æ•°æ®åº“è¿æ¥ç®¡ç†

```rust
pub struct DatabaseManager {
    pool: PgPool,
    config: DatabaseConfig,
}

impl DatabaseManager {
    pub async fn new(config: DatabaseConfig) -> SchedulerResult<Self> {
        let pool = PgPoolOptions::new()
            .max_connections(config.max_connections)
            .min_connections(config.min_connections)
            .acquire_timeout(Duration::from_secs(config.connection_timeout))
            .idle_timeout(Duration::from_secs(config.idle_timeout))
            .connect(&config.url)
            .await?;
            
        Ok(Self { pool, config })
    }
    
    pub async fn health_check(&self) -> SchedulerResult<()> {
        sqlx::query("SELECT 1")
            .fetch_one(&self.pool)
            .await?;
        Ok(())
    }
}
```

## ğŸš€ APIå¼€å‘æŒ‡å—

### è·¯ç”±å®šä¹‰

```rust
use axum::{
    routing::{get, post, put, delete},
    Router,
};

pub fn create_routes(state: AppState) -> Router {
    Router::new()
        .route("/health", get(health_check))
        .nest("/api", api_routes())
        .layer(cors_layer())
        .layer(auth_layer())
        .layer(rate_limit_layer())
        .with_state(state)
}

fn api_routes() -> Router<AppState> {
    Router::new()
        .nest("/tasks", task_routes())
        .nest("/workers", worker_routes())
        .nest("/system", system_routes())
}

fn task_routes() -> Router<AppState> {
    Router::new()
        .route("/", get(list_tasks).post(create_task))
        .route("/:id", get(get_task).put(update_task).delete(delete_task))
        .route("/:id/trigger", post(trigger_task))
        .route("/:id/pause", post(pause_task))
        .route("/:id/resume", post(resume_task))
}
```

### è¯·æ±‚å¤„ç†å™¨å®ç°

```rust
#[derive(Debug, Deserialize)]
pub struct CreateTaskRequest {
    pub name: String,
    pub description: Option<String>,
    pub task_type: String,
    pub executor: String,
    pub command: String,
    pub arguments: Option<Vec<String>>,
    pub schedule: Option<String>,
    pub priority: Option<TaskPriority>,
    pub retry_count: Option<u32>,
    pub timeout_seconds: Option<u32>,
}

pub async fn create_task(
    State(app_state): State<AppState>,
    Json(request): Json<CreateTaskRequest>,
) -> Result<Json<ApiResponse<Task>>, ApiError> {
    // 1. è¾“å…¥éªŒè¯
    validate_create_task_request(&request)?;
    
    // 2. ä¸šåŠ¡é€»è¾‘å¤„ç†
    let task = app_state.task_service
        .create_task(request)
        .await?;
    
    // 3. å“åº”æ„å»º
    Ok(Json(ApiResponse::success(task)))
}

// é”™è¯¯å¤„ç†
impl From<SchedulerError> for ApiError {
    fn from(err: SchedulerError) -> Self {
        match err {
            SchedulerError::ValidationError(msg) => ApiError::BadRequest(msg),
            SchedulerError::NotFoundError(msg) => ApiError::NotFound(msg),
            SchedulerError::DatabaseError(_) => ApiError::InternalServerError("æ•°æ®åº“é”™è¯¯".to_string()),
            _ => ApiError::InternalServerError("å†…éƒ¨æœåŠ¡å™¨é”™è¯¯".to_string()),
        }
    }
}
```

### ä¸­é—´ä»¶å¼€å‘

```rust
// è®¤è¯ä¸­é—´ä»¶
pub fn auth_middleware() -> impl Layer<Router> {
    middleware::from_fn(auth_handler)
}

async fn auth_handler(
    headers: HeaderMap,
    request: Request,
    next: Next,
) -> Result<Response, ApiError> {
    // 1. æå–è®¤è¯ä¿¡æ¯
    let auth_header = headers.get("Authorization")
        .ok_or_else(|| ApiError::Unauthorized("ç¼ºå°‘è®¤è¯å¤´".to_string()))?;
    
    // 2. éªŒè¯ä»¤ç‰Œ
    let token = extract_bearer_token(auth_header)?;
    let claims = validate_jwt_token(&token)?;
    
    // 3. æ·»åŠ ç”¨æˆ·ä¸Šä¸‹æ–‡
    let mut request = request;
    request.extensions_mut().insert(UserContext::from(claims));
    
    Ok(next.run(request).await)
}

// é€Ÿç‡é™åˆ¶ä¸­é—´ä»¶
pub fn rate_limit_middleware() -> impl Layer<Router> {
    ServiceBuilder::new()
        .layer(HandleErrorLayer::new(handle_rate_limit_error))
        .layer(BufferLayer::new(1024))
        .layer(RateLimitLayer::new(100, Duration::from_secs(60)))
}
```

## âš¡ ä»»åŠ¡è°ƒåº¦å¼€å‘

### è°ƒåº¦å™¨æ ¸å¿ƒå®ç°

```rust
pub struct TaskScheduler {
    task_repository: Arc<dyn TaskRepository>,
    worker_repository: Arc<dyn WorkerRepository>,
    message_queue: Arc<dyn MessageQueue>,
    strategy: Box<dyn SchedulingStrategy>,
    config: SchedulerConfig,
}

impl TaskScheduler {
    pub async fn start(&self) -> SchedulerResult<()> {
        info!("å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨");
        
        // 1. å¯åŠ¨è°ƒåº¦å¾ªç¯
        let scheduler_handle = self.start_scheduling_loop();
        
        // 2. å¯åŠ¨å¿ƒè·³æ£€æŸ¥
        let heartbeat_handle = self.start_heartbeat_monitor();
        
        // 3. å¯åŠ¨æ•…éšœæ¢å¤
        let recovery_handle = self.start_recovery_service();
        
        // ç­‰å¾…æ‰€æœ‰æœåŠ¡å®Œæˆ
        try_join!(scheduler_handle, heartbeat_handle, recovery_handle)?;
        
        Ok(())
    }
    
    async fn start_scheduling_loop(&self) -> SchedulerResult<()> {
        let mut interval = interval(Duration::from_secs(self.config.scheduling_interval));
        
        loop {
            interval.tick().await;
            
            if let Err(e) = self.schedule_pending_tasks().await {
                error!("è°ƒåº¦å¾ªç¯é”™è¯¯: {}", e);
            }
        }
    }
    
    async fn schedule_pending_tasks(&self) -> SchedulerResult<()> {
        // 1. è·å–å¾…è°ƒåº¦ä»»åŠ¡
        let pending_tasks = self.task_repository
            .find_by_status(TaskStatus::Pending)
            .await?;
        
        // 2. æ£€æŸ¥ä¾èµ–å…³ç³»
        let ready_tasks = self.filter_ready_tasks(pending_tasks).await?;
        
        // 3. é€‰æ‹©Worker
        for task in ready_tasks {
            if let Some(worker) = self.strategy.select_worker(&task).await? {
                self.assign_task_to_worker(&task, &worker).await?;
            }
        }
        
        Ok(())
    }
}
```

### è°ƒåº¦ç­–ç•¥å®ç°

```rust
#[async_trait]
pub trait SchedulingStrategy: Send + Sync {
    async fn select_worker(&self, task: &Task) -> SchedulerResult<Option<WorkerInfo>>;
}

// è´Ÿè½½å‡è¡¡ç­–ç•¥
pub struct LoadBalancingStrategy {
    worker_repository: Arc<dyn WorkerRepository>,
}

#[async_trait]
impl SchedulingStrategy for LoadBalancingStrategy {
    async fn select_worker(&self, task: &Task) -> SchedulerResult<Option<WorkerInfo>> {
        let available_workers = self.worker_repository
            .find_available_workers(&task.task_type)
            .await?;
        
        // é€‰æ‹©è´Ÿè½½æœ€ä½çš„Worker
        let selected_worker = available_workers
            .into_iter()
            .min_by_key(|w| w.current_task_count)
            .map(|w| w.clone());
        
        Ok(selected_worker)
    }
}

// ä¼˜å…ˆçº§ç­–ç•¥
pub struct PrioritySchedulingStrategy {
    load_balancer: LoadBalancingStrategy,
}

#[async_trait]
impl SchedulingStrategy for PrioritySchedulingStrategy {
    async fn select_worker(&self, task: &Task) -> SchedulerResult<Option<WorkerInfo>> {
        // ä¼˜å…ˆçº§ä»»åŠ¡ä¼˜å…ˆåˆ†é…
        match task.priority {
            TaskPriority::Critical => {
                // ç«‹å³åˆ†é…ç»™æœ€ç©ºé—²çš„Worker
                self.load_balancer.select_worker(task).await
            },
            _ => {
                // å¸¸è§„è´Ÿè½½å‡è¡¡
                self.load_balancer.select_worker(task).await
            }
        }
    }
}
```

## ğŸ‘· Workerå¼€å‘æŒ‡å—

### WorkeræœåŠ¡å®ç°

```rust
pub struct WorkerService {
    id: String,
    config: WorkerConfig,
    executor_registry: Arc<dyn ExecutorRegistry>,
    heartbeat_manager: Arc<HeartbeatManager>,
    task_execution: Arc<TaskExecution>,
    lifecycle: WorkerLifecycle,
}

impl WorkerService {
    pub async fn start(&self) -> SchedulerResult<()> {
        info!("å¯åŠ¨WorkeræœåŠ¡: {}", self.id);
        
        // 1. æ³¨å†ŒWorker
        self.register_worker().await?;
        
        // 2. å¯åŠ¨å¿ƒè·³
        let heartbeat_handle = self.heartbeat_manager.start();
        
        // 3. å¯åŠ¨ä»»åŠ¡ç›‘å¬
        let task_listener_handle = self.start_task_listener();
        
        // 4. å¯åŠ¨å¥åº·æ£€æŸ¥
        let health_check_handle = self.start_health_check();
        
        // ç­‰å¾…æœåŠ¡å®Œæˆ
        try_join!(heartbeat_handle, task_listener_handle, health_check_handle)?;
        
        Ok(())
    }
    
    async fn start_task_listener(&self) -> SchedulerResult<()> {
        let consumer = self.message_queue
            .create_consumer(&format!("worker.{}", self.id))
            .await?;
        
        while let Some(message) = consumer.next().await {
            match self.handle_task_message(message).await {
                Ok(_) => info!("ä»»åŠ¡å¤„ç†å®Œæˆ"),
                Err(e) => error!("ä»»åŠ¡å¤„ç†å¤±è´¥: {}", e),
            }
        }
        
        Ok(())
    }
    
    async fn handle_task_message(&self, message: Message) -> SchedulerResult<()> {
        let task_execution_request: TaskExecutionRequest = message.deserialize()?;
        
        // æ‰§è¡Œä»»åŠ¡
        self.task_execution
            .execute(task_execution_request)
            .await?;
        
        Ok(())
    }
}
```

### ä»»åŠ¡æ‰§è¡Œå™¨å®ç°

```rust
#[async_trait]
pub trait TaskExecutor: Send + Sync {
    async fn execute(&self, task: &Task) -> SchedulerResult<TaskResult>;
    async fn cancel(&self, task_run_id: i64) -> SchedulerResult<()>;
    fn supports_task_type(&self, task_type: &str) -> bool;
}

// Shellæ‰§è¡Œå™¨
pub struct ShellExecutor {
    config: ShellExecutorConfig,
}

#[async_trait]
impl TaskExecutor for ShellExecutor {
    async fn execute(&self, task: &Task) -> SchedulerResult<TaskResult> {
        let mut command = Command::new("sh");
        command.arg("-c").arg(&task.command);
        
        // è®¾ç½®ç¯å¢ƒå˜é‡
        if let Some(env_vars) = &task.environment {
            for (key, value) in env_vars {
                command.env(key, value);
            }
        }
        
        // è®¾ç½®å·¥ä½œç›®å½•
        if let Some(working_dir) = &task.working_directory {
            command.current_dir(working_dir);
        }
        
        // æ‰§è¡Œå‘½ä»¤
        let start_time = Utc::now();
        let output = command.output().await
            .map_err(|e| SchedulerError::ExecutionError(e.to_string()))?;
        let end_time = Utc::now();
        
        let result = TaskResult {
            exit_code: output.status.code(),
            stdout: String::from_utf8_lossy(&output.stdout).to_string(),
            stderr: String::from_utf8_lossy(&output.stderr).to_string(),
            execution_time: (end_time - start_time).num_milliseconds(),
            started_at: start_time,
            completed_at: end_time,
        };
        
        Ok(result)
    }
    
    fn supports_task_type(&self, task_type: &str) -> bool {
        task_type == "shell" || task_type == "bash"
    }
}

// HTTPæ‰§è¡Œå™¨
pub struct HttpExecutor {
    client: reqwest::Client,
    config: HttpExecutorConfig,
}

#[async_trait]
impl TaskExecutor for HttpExecutor {
    async fn execute(&self, task: &Task) -> SchedulerResult<TaskResult> {
        let request_config: HttpRequestConfig = serde_json::from_str(&task.command)
            .map_err(|e| SchedulerError::ValidationError(e.to_string()))?;
        
        let start_time = Utc::now();
        
        let mut request_builder = match request_config.method.as_str() {
            "GET" => self.client.get(&request_config.url),
            "POST" => self.client.post(&request_config.url),
            "PUT" => self.client.put(&request_config.url),
            "DELETE" => self.client.delete(&request_config.url),
            _ => return Err(SchedulerError::ValidationError("ä¸æ”¯æŒçš„HTTPæ–¹æ³•".to_string())),
        };
        
        // æ·»åŠ è¯·æ±‚å¤´
        if let Some(headers) = &request_config.headers {
            for (key, value) in headers {
                request_builder = request_builder.header(key, value);
            }
        }
        
        // æ·»åŠ è¯·æ±‚ä½“
        if let Some(body) = &request_config.body {
            request_builder = request_builder.json(body);
        }
        
        // å‘é€è¯·æ±‚
        let response = request_builder
            .timeout(Duration::from_secs(task.timeout_seconds as u64))
            .send()
            .await
            .map_err(|e| SchedulerError::ExecutionError(e.to_string()))?;
        
        let end_time = Utc::now();
        let status_code = response.status().as_u16();
        let response_body = response.text().await
            .map_err(|e| SchedulerError::ExecutionError(e.to_string()))?;
        
        let result = TaskResult {
            exit_code: Some(status_code as i32),
            stdout: response_body,
            stderr: String::new(),
            execution_time: (end_time - start_time).num_milliseconds(),
            started_at: start_time,
            completed_at: end_time,
        };
        
        Ok(result)
    }
    
    fn supports_task_type(&self, task_type: &str) -> bool {
        task_type == "http" || task_type == "webhook"
    }
}
```

## ğŸ“Š ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### æŒ‡æ ‡æ”¶é›†

```rust
use prometheus::{Counter, Histogram, Gauge, Registry};

pub struct MetricsCollector {
    registry: Registry,
    task_counter: Counter,
    task_duration: Histogram,
    active_workers: Gauge,
    queue_depth: Gauge,
}

impl MetricsCollector {
    pub fn new() -> Self {
        let registry = Registry::new();
        
        let task_counter = Counter::new(
            "scheduler_tasks_total",
            "Total number of tasks processed"
        ).unwrap();
        
        let task_duration = Histogram::with_opts(
            prometheus::HistogramOpts::new(
                "scheduler_task_duration_seconds",
                "Task execution duration in seconds"
            ).buckets(vec![0.1, 0.5, 1.0, 5.0, 10.0, 30.0, 60.0])
        ).unwrap();
        
        registry.register(Box::new(task_counter.clone())).unwrap();
        registry.register(Box::new(task_duration.clone())).unwrap();
        
        Self {
            registry,
            task_counter,
            task_duration,
            active_workers: Gauge::new("scheduler_active_workers", "Number of active workers").unwrap(),
            queue_depth: Gauge::new("scheduler_queue_depth", "Message queue depth").unwrap(),
        }
    }
    
    pub fn record_task_completion(&self, duration: f64) {
        self.task_counter.inc();
        self.task_duration.observe(duration);
    }
    
    pub fn export_metrics(&self) -> String {
        let encoder = prometheus::TextEncoder::new();
        let metric_families = self.registry.gather();
        encoder.encode_to_string(&metric_families).unwrap()
    }
}
```

### åˆ†å¸ƒå¼è¿½è¸ª

```rust
use opentelemetry::{global, trace::{Tracer, Span}};
use tracing_opentelemetry::OpenTelemetrySpanExt;

pub struct TracingContext {
    tracer: Box<dyn Tracer + Send + Sync>,
}

impl TracingContext {
    pub fn new() -> Self {
        let tracer = global::tracer("scheduler");
        Self { tracer }
    }
    
    pub fn start_span(&self, name: &str) -> impl Span {
        self.tracer.start(name)
    }
    
    pub async fn trace_task_execution<F, R>(&self, task_id: i64, f: F) -> R
    where
        F: Future<Output = R>,
    {
        let span = self.start_span("task_execution");
        span.set_attribute(KeyValue::new("task.id", task_id));
        
        async move {
            let _guard = span.enter();
            f.await
        }.await
    }
}
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use mockall::predicate::*;
    use crate::testing_utils::*;
    
    #[tokio::test]
    async fn test_create_task_success() {
        // Arrange
        let mut mock_repository = MockTaskRepository::new();
        mock_repository
            .expect_save()
            .with(predicate::always())
            .times(1)
            .returning(|task| Ok(task.clone()));
        
        let service = TaskService::new(Arc::new(mock_repository));
        let request = CreateTaskRequest {
            name: "test_task".to_string(),
            executor: "shell".to_string(),
            command: "echo hello".to_string(),
            ..Default::default()
        };
        
        // Act
        let result = service.create_task(request).await;
        
        // Assert
        assert!(result.is_ok());
        let task = result.unwrap();
        assert_eq!(task.name, "test_task");
    }
    
    #[tokio::test]
    async fn test_create_task_validation_error() {
        let mock_repository = MockTaskRepository::new();
        let service = TaskService::new(Arc::new(mock_repository));
        
        let request = CreateTaskRequest {
            name: "".to_string(), // ç©ºåç§°åº”è¯¥å¯¼è‡´éªŒè¯é”™è¯¯
            ..Default::default()
        };
        
        let result = service.create_task(request).await;
        
        assert!(result.is_err());
        match result.unwrap_err() {
            SchedulerError::ValidationError(_) => (),
            _ => panic!("æœŸæœ›éªŒè¯é”™è¯¯"),
        }
    }
}
```

### é›†æˆæµ‹è¯•

```rust
// tests/integration_tests.rs
use scheduler_testing_utils::TestContainers;
use sqlx::PgPool;

#[tokio::test]
async fn test_task_lifecycle_integration() {
    // å¯åŠ¨æµ‹è¯•å®¹å™¨
    let containers = TestContainers::start().await;
    let pool = containers.postgres_pool().await;
    
    // è¿è¡Œè¿ç§»
    sqlx::migrate!("./migrations").run(&pool).await.unwrap();
    
    // åˆ›å»ºæœåŠ¡å®ä¾‹
    let task_repo = PostgreSQLTaskRepository::new(pool.clone());
    let task_service = TaskService::new(Arc::new(task_repo));
    
    // æµ‹è¯•ä»»åŠ¡åˆ›å»º
    let create_request = CreateTaskRequest {
        name: "integration_test_task".to_string(),
        executor: "shell".to_string(),
        command: "echo 'integration test'".to_string(),
        ..Default::default()
    };
    
    let created_task = task_service.create_task(create_request).await.unwrap();
    assert!(created_task.id.is_some());
    
    // æµ‹è¯•ä»»åŠ¡æŸ¥è¯¢
    let found_task = task_service.get_task(created_task.id.unwrap()).await.unwrap();
    assert_eq!(found_task.name, "integration_test_task");
    
    // æµ‹è¯•ä»»åŠ¡æ›´æ–°
    let update_request = UpdateTaskRequest {
        description: Some("Updated description".to_string()),
        ..Default::default()
    };
    
    let updated_task = task_service.update_task(created_task.id.unwrap(), update_request).await.unwrap();
    assert_eq!(updated_task.description.unwrap(), "Updated description");
    
    // æµ‹è¯•ä»»åŠ¡åˆ é™¤
    task_service.delete_task(created_task.id.unwrap()).await.unwrap();
    let deleted_task = task_service.get_task(created_task.id.unwrap()).await;
    assert!(deleted_task.is_err());
}
```

### æ€§èƒ½æµ‹è¯•

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_task_creation(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let service = setup_task_service();
    
    c.bench_function("create_task", |b| {
        b.to_async(&rt).iter(|| async {
            let request = CreateTaskRequest {
                name: format!("bench_task_{}", black_box(rand::random::<u32>())),
                executor: "shell".to_string(),
                command: "echo hello".to_string(),
                ..Default::default()
            };
            
            black_box(service.create_task(request).await.unwrap())
        })
    });
}

criterion_group!(benches, benchmark_task_creation);
criterion_main!(benches);
```

## ğŸš€ éƒ¨ç½²ä¸è¿ç»´

### DockeråŒ–éƒ¨ç½²

```dockerfile
# Dockerfile.scheduler
FROM rust:1.70-slim as builder

WORKDIR /app
COPY Cargo.toml Cargo.lock ./
COPY crates ./crates
COPY src ./src

# æ„å»ºå‘å¸ƒç‰ˆæœ¬
RUN cargo build --release --bin scheduler

FROM debian:bullseye-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl1.1 \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/target/release/scheduler /usr/local/bin/scheduler

# åˆ›å»ºç”¨æˆ·
RUN useradd -m -u 1001 scheduler
USER scheduler

EXPOSE 8080
CMD ["scheduler"]
```

### Kuberneteséƒ¨ç½²

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scheduler
  labels:
    app: scheduler
spec:
  replicas: 3
  selector:
    matchLabels:
      app: scheduler
  template:
    metadata:
      labels:
        app: scheduler
    spec:
      containers:
      - name: scheduler
        image: scheduler:latest
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: scheduler-secrets
              key: database-url
        - name: RABBITMQ_URL
          valueFrom:
            secretKeyRef:
              name: scheduler-secrets
              key: rabbitmq-url
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: scheduler-service
spec:
  selector:
    app: scheduler
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: ClusterIP
```

## ğŸ”§ è°ƒè¯•ä¸æ•…éšœæ’é™¤

### æ—¥å¿—é…ç½®

```rust
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_logging() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::registry()
        .with(
            tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| "info".into()),
        )
        .with(tracing_subscriber::fmt::layer().json())
        .with(tracing_opentelemetry::layer())
        .init();
    
    Ok(())
}
```

### è°ƒè¯•å·¥å…·

```bash
# å®æ—¶æ—¥å¿—ç›‘æ§
kubectl logs -f deployment/scheduler

# æ€§èƒ½åˆ†æ
cargo flamegraph --bin scheduler

# å†…å­˜åˆ†æ
valgrind --tool=massif target/debug/scheduler

# ç½‘ç»œè°ƒè¯•
tcpdump -i any port 5672  # RabbitMQæµé‡
tcpdump -i any port 5432  # PostgreSQLæµé‡
```

### å¸¸è§é—®é¢˜è§£å†³

```rust
// è¿æ¥æ± è€—å°½
impl DatabaseManager {
    pub async fn check_pool_health(&self) -> SchedulerResult<PoolHealth> {
        let pool_state = self.pool.state();
        
        if pool_state.idle_connections == 0 && pool_state.size >= pool_state.max_size {
            warn!("æ•°æ®åº“è¿æ¥æ± è€—å°½: idle={}, size={}, max_size={}", 
                  pool_state.idle_connections, pool_state.size, pool_state.max_size);
        }
        
        Ok(PoolHealth {
            idle_connections: pool_state.idle_connections,
            active_connections: pool_state.size - pool_state.idle_connections,
            max_connections: pool_state.max_size,
        })
    }
}

// å†…å­˜æ³„æ¼æ£€æµ‹
pub struct ResourceTracker {
    active_tasks: Arc<AtomicUsize>,
    active_connections: Arc<AtomicUsize>,
}

impl ResourceTracker {
    pub fn track_task(&self) -> TaskGuard {
        self.active_tasks.fetch_add(1, Ordering::SeqCst);
        TaskGuard { tracker: self.clone() }
    }
}

impl Drop for TaskGuard {
    fn drop(&mut self) {
        self.tracker.active_tasks.fetch_sub(1, Ordering::SeqCst);
    }
}
```

---

æœ¬å¼€å‘è€…æŒ‡å—æä¾›äº†åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿçš„å®Œæ•´å¼€å‘æµç¨‹ï¼Œä»ç¯å¢ƒè®¾ç½®åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨ç”Ÿå‘½å‘¨æœŸæŒ‡å¯¼ã€‚å¼€å‘è€…å¯ä»¥å‚è€ƒæ­¤æŒ‡å—å¿«é€Ÿä¸Šæ‰‹å¹¶æ·±å…¥ç†è§£ç³»ç»Ÿæ¶æ„ã€‚

**æœ€åæ›´æ–°**: 2025-08-21  
**æŒ‡å—ç‰ˆæœ¬**: v1.0